## 一、背景

随着 AI 在人机交互领域的发展，**情绪感知（Affective Computing）** 成为重要研究方向之一。本次大作业要求设计并实现一个 **情绪状态识别与表达系统**，强调：

- 模糊输入  
- 连续状态  
- 非确定性输出  

---

## 二、作业目标

请你实现一个 **情绪状态建模模块**，能够：

1. 从用户的自然输入中推断其情绪状态  
2. 将情绪抽象为**连续参数空间**  
3. 以可视化方式展示情绪变化趋势  

> ⚠️ 注意：  
> 本作业**不要求直接控制具体视觉对象**，重点在“情绪表达的合理性”。

---

## 三、功能要求

### 1️⃣ 输入层（任选其一或组合）

- 🎤 语音输入（推荐）  
- 📷 摄像头（面部表情 / 头部姿态）  
- ⌨️ 手动输入（作为兜底方案）  

要求：  
- 输入具有**不稳定性**  
- 允许噪声、误判、波动  

---

### 2️⃣ 情绪建模

请将情绪表示为一个抽象结构，例如：

```json
{
  "emotion": "warm",
  "valence": 0.0,
  "arousal": 0.0,
  "confidence": 0.0
}
```
* emotion：离散情绪类别（数量不宜过多）
* valence：情绪正负性（0.0 ~ 1.0）
* arousal：激活强度（0.0 ~ 1.0）
* confidence：识别稳定度（0.0 ~ 1.0）
> 情绪不要求“准确”，但要求连续、合理、有惯性。

---

### 3️⃣ 状态更新逻辑
* 情绪变化需平滑（禁止剧烈跳变）
* 允许短时间“矛盾状态”
* 鼓励使用：
  * 滑动平均
  * 低通滤波
  * 状态机

---

### 4️⃣ 本地可视化（仅用于调试）
你可以自行设计一个简单界面，用于展示：
* 当前情绪状态
* 情绪变化曲线
* 情绪稳定度

> ⚠️ 注意：
> 这些可视化不一定会作为最终成果的一部分。

---

## 四、输出接口要求（非常重要）
请定义外部使用函数，将情绪状态以 JSON 数据结构 的形式返回给调用方，例如：
```json
{
  "source": "emotion-module",
  "timestamp": 1700000000,
  "emotion": "warm",
  "valence": 0.72,
  "arousal": 0.38,
  "confidence": 0.81
}
```

---

## 五、提示
* 不要试图“精确控制结果”
* 情绪本身是模糊的
* **让系统保留不确定性，往往更真实**